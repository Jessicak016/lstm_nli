{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bright-corps",
   "metadata": {},
   "source": [
    "## Natural Language Inference Task: LSTM & Sum Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-roman",
   "metadata": {},
   "source": [
    "### Tensorflow LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-tunnel",
   "metadata": {},
   "source": [
    "If there are no processed data in the directory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prostate-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('snli/snli_1.0_train.txt', delimiter = \"\\t\")\n",
    "df_dev = pd.read_csv('snli/snli_1.0_dev.txt', delimiter = \"\\t\")\n",
    "df_test = pd.read_csv('snli/snli_1.0_test.txt', delimiter = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "developmental-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"gold_label\", \"sentence1\", \"sentence2\"]].dropna(axis=0).rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "df_dev = df_dev[[\"gold_label\", \"sentence1\", \"sentence2\"]].dropna(axis=0).rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "df_test = df_test[[\"gold_label\", \"sentence1\", \"sentence2\"]].dropna(axis=0).rename(columns={\"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"})\n",
    "\n",
    "df_train = df_train[df_train[\"gold_label\"] != \"-\"]\n",
    "df_dev = df_dev[df_dev[\"gold_label\"] != \"-\"]\n",
    "df_test = df_test[df_test[\"gold_label\"] != \"-\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-brief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549361, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reasonable-duncan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9842, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "olympic-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9824, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tender-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the training size\n",
    "training_data_length = 45948\n",
    "df_train = df_train.iloc[:training_data_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fresh-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sought-baptist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0        neutral  A person on a horse jumps over a broken down a...   \n",
       "1  contradiction  A person on a horse jumps over a broken down a...   \n",
       "\n",
       "                                          hypothesis  \n",
       "0  A person is training his horse for a competition.  \n",
       "1      A person is at a diner, ordering an omelette.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True, split=' ', char_level=False, oov_token=None,\n",
    "                      document_count=0)\n",
    "\n",
    "tokenizer.fit_on_texts(df_train[\"premise\"].values + df_train[\"hypothesis\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flush-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (df_train[\"premise\"]+df_train[\"hypothesis\"]+df_dev[\"premise\"]+df_dev[\"hypothesis\"]+df_test[\"premise\"]+df_test[\"hypothesis\"])\n",
    "\n",
    "max_length = int(df_all.str.split().str.len().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becoming-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transformation to sequences and padding\n",
    "\n",
    "train_prem_encoded = pad_sequences(tokenizer.texts_to_sequences(df_train[\"premise\"]),\n",
    "                                   maxlen=max_length,\n",
    "                                   padding=\"post\")\n",
    "train_hyp_encoded = pad_sequences(tokenizer.texts_to_sequences(df_train[\"hypothesis\"]),\n",
    "                                  maxlen=max_length, \n",
    "                                  padding=\"post\")\n",
    "\n",
    "dev_prem_encoded = pad_sequences(tokenizer.texts_to_sequences(df_dev[\"premise\"]),\n",
    "                                 maxlen=max_length,\n",
    "                                 padding=\"post\")\n",
    "dev_hyp_encoded = pad_sequences(tokenizer.texts_to_sequences(df_dev[\"hypothesis\"]),\n",
    "                                maxlen=max_length,\n",
    "                                padding=\"post\")\n",
    "\n",
    "test_prem_encoded = pad_sequences(tokenizer.texts_to_sequences(df_test[\"premise\"]),\n",
    "                                  maxlen=max_length,\n",
    "                                  padding=\"post\")\n",
    "test_hyp_encoded = pad_sequences(tokenizer.texts_to_sequences(df_test[\"hypothesis\"]),\n",
    "                                 maxlen=max_length,\n",
    "                                 padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "underlying-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "labels = list(df_train[\"gold_label\"].value_counts().index)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "df_train[\"gold_label\"] = le.transform(df_train[\"gold_label\"])\n",
    "df_dev[\"gold_label\"] = le.transform(df_dev[\"gold_label\"])\n",
    "df_test[\"gold_label\"] = le.transform(df_test[\"gold_label\"])\n",
    "\n",
    "train_labels = df_train[\"gold_label\"].values\n",
    "dev_labels = df_dev[\"gold_label\"].values\n",
    "test_labels = df_test[\"gold_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "saving-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, ..., 0, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepted-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, concatenate, Input, Dense, Embedding, Bidirectional, Dropout, Attention, TimeDistributed, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-circular",
   "metadata": {},
   "source": [
    "### Create Word Embeddings using Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-welsh",
   "metadata": {},
   "source": [
    "The glove.840B.300d.txt file was retrieved from the kaggle data page: https://www.kaggle.com/takuok/glove840b300dtxt.\n",
    "The below portion of the code, which processes Glove and creates word embedding matrix, was adapted from KERAS SNLI baseline example (link: https://github.com/Smerity/keras_snli/blob/master/snli_rnn.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "resistant-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "embedding_hidden_size = 300 # needs to be 300 since the dimension of Glove vector embeddings is (300, )\n",
    "n_labels = len(df_train[\"gold_label\"].value_counts().index)\n",
    "vocab_size = len(tokenizer.word_counts)\n",
    "activation_function = \"relu\" # maybe try tanh like the one in the paper \n",
    "dropout_lstm = 0.5\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adadelta'\n",
    "batch_size = 1\n",
    "num_epoch = 1\n",
    "l2_penalty_rate = 0.001\n",
    "l2_penalty = l2(l2_penalty_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-cincinnati",
   "metadata": {},
   "source": [
    "##### If there is no processed glove embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "expensive-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open glove.840B.300d.txt and preprocess it to make it usable\n",
    "# this will take some time \n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "arranged-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing from GloVe: man's\n",
      "Missing from GloVe: woman's\n",
      "Missing from GloVe: children's\n",
      "Missing from GloVe: girl's\n",
      "Missing from GloVe: farmer's\n",
      "Missing from GloVe: women's\n",
      "Missing from GloVe: child's\n",
      "Missing from GloVe: giraffe's\n",
      "Missing from GloVe: there's\n",
      "Missing from GloVe: streeta\n",
      "Missing from GloVe: people's\n",
      "Missing from GloVe: boy's\n",
      "Missing from GloVe: who's\n",
      "Missing from GloVe: person's\n",
      "Missing from GloVe: mother's\n",
      "Missing from GloVe: watera\n",
      "Missing from GloVe: someone's\n",
      "Missing from GloVe: he's\n",
      "Missing from GloVe: dad's\n",
      "Missing from GloVe: they're\n",
      "Missing from GloVe: bikea\n",
      "Missing from GloVe: horse's\n",
      "Missing from GloVe: john's\n",
      "Missing from GloVe: american's\n",
      "Missing from GloVe: says'\n",
      "Missing from GloVe: isn't\n",
      "Missing from GloVe: joule'\n",
      "Missing from GloVe: rachofsky\n",
      "Missing from GloVe: beacha\n",
      "Missing from GloVe: amazementa\n",
      "Missing from GloVe: realtors'\n",
      "Missing from GloVe: rottwieler\n",
      "Missing from GloVe: groom's\n",
      "Missing from GloVe: waterthe\n",
      "Missing from GloVe: buildinga\n",
      "Missing from GloVe: friend's\n",
      "Missing from GloVe: couchthe\n",
      "Missing from GloVe: rocksa\n",
      "Missing from GloVe: sidewalka\n",
      "Missing from GloVe: mcdonald's\n",
      "Missing from GloVe: rollerskaters\n",
      "Missing from GloVe: stationtwo\n",
      "Missing from GloVe: alleywaya\n",
      "Missing from GloVe: joe's\n",
      "Missing from GloVe: chef's\n",
      "Missing from GloVe: aren't\n",
      "Missing from GloVe: other's\n",
      "Missing from GloVe: crasha\n",
      "Missing from GloVe: coucha\n",
      "Missing from GloVe: a'\n",
      "Missing from GloVe: nathalie's\n",
      "Missing from GloVe: artist's\n",
      "Missing from GloVe: others'\n",
      "Missing from GloVe: poola\n",
      "Missing from GloVe: she's\n",
      "Missing from GloVe: chaira\n",
      "Missing from GloVe: dog's\n",
      "Missing from GloVe: swingthe\n",
      "Missing from GloVe: racqueta\n",
      "Missing from GloVe: streetthe\n",
      "Missing from GloVe: water's\n",
      "Missing from GloVe: fielda\n",
      "Missing from GloVe: gentlemen's\n",
      "Missing from GloVe: sidewalktwo\n",
      "Missing from GloVe: picturethe\n",
      "Missing from GloVe: himselfa\n",
      "Missing from GloVe: racea\n",
      "Missing from GloVe: areathe\n",
      "Missing from GloVe: fieldthe\n",
      "Missing from GloVe: men's\n",
      "Missing from GloVe: buildingthe\n",
      "Missing from GloVe: backgrounda\n",
      "Missing from GloVe: client's\n",
      "Missing from GloVe: owner's\n",
      "Missing from GloVe: parasailer\n",
      "Missing from GloVe: what's\n",
      "Missing from GloVe: shoegasm\n",
      "Missing from GloVe: boarda\n",
      "Missing from GloVe: overheadtwo\n",
      "Missing from GloVe: motorcylist\n",
      "Missing from GloVe: grasstwo\n",
      "Missing from GloVe: captain's\n",
      "Missing from GloVe: mealthe\n",
      "Missing from GloVe: wallthe\n",
      "Missing from GloVe: beachthe\n",
      "Missing from GloVe: wavea\n",
      "Missing from GloVe: countrya\n",
      "Missing from GloVe: shopa\n",
      "Missing from GloVe: boys'\n",
      "Missing from GloVe: waterkids\n",
      "Missing from GloVe: marketthe\n",
      "Missing from GloVe: snowa\n",
      "Missing from GloVe: picturepeople\n",
      "Missing from GloVe: hillthree\n",
      "Missing from GloVe: grounda\n",
      "Missing from GloVe: guy's\n",
      "Missing from GloVe: treea\n",
      "Missing from GloVe: parasurfer\n",
      "Missing from GloVe: playgrounda\n",
      "Missing from GloVe: girlthe\n",
      "Missing from GloVe: sweatera\n",
      "Missing from GloVe: coursea\n",
      "Missing from GloVe: strollera\n",
      "Missing from GloVe: camerathe\n",
      "Missing from GloVe: smilinga\n",
      "Missing from GloVe: playingthe\n",
      "Missing from GloVe: carthe\n",
      "Missing from GloVe: ballthe\n",
      "Missing from GloVe: girls'\n",
      "Missing from GloVe: signthe\n",
      "Missing from GloVe: master's\n",
      "Missing from GloVe: band's\n",
      "Missing from GloVe: boogieboard\n",
      "Missing from GloVe: stagea\n",
      "Missing from GloVe: picturefour\n",
      "Missing from GloVe: world's\n",
      "Missing from GloVe: day's\n",
      "Missing from GloVe: equipmentthe\n",
      "Missing from GloVe: sister's\n",
      "Missing from GloVe: rodeoa\n",
      "Missing from GloVe: parents'\n",
      "Missing from GloVe: outdoorsthe\n",
      "Missing from GloVe: smilea\n",
      "Missing from GloVe: downhilla\n",
      "Missing from GloVe: santa's\n",
      "Missing from GloVe: poolthe\n",
      "Missing from GloVe: pipethe\n",
      "Missing from GloVe: seatthe\n",
      "Missing from GloVe: bytwo\n",
      "Missing from GloVe: ambuc\n",
      "Missing from GloVe: bikethe\n",
      "Missing from GloVe: bird's\n",
      "Missing from GloVe: fieldtwo\n",
      "Missing from GloVe: streetthere\n",
      "Missing from GloVe: waterthere\n",
      "Missing from GloVe: buildingthere\n",
      "Missing from GloVe: hasn't\n",
      "Missing from GloVe: telescopea\n",
      "Missing from GloVe: i'm\n",
      "Missing from GloVe: baby's\n",
      "Missing from GloVe: grassthe\n",
      "Missing from GloVe: grandson's\n",
      "Missing from GloVe: parent's\n",
      "Missing from GloVe: wallthere\n",
      "Missing from GloVe: hillthe\n",
      "Missing from GloVe: building's\n",
      "Missing from GloVe: husband's\n",
      "Missing from GloVe: lakea\n",
      "Missing from GloVe: adult's\n",
      "Missing from GloVe: grandma's\n",
      "Missing from GloVe: microphonethe\n",
      "Missing from GloVe: rollerskater\n",
      "Missing from GloVe: eventa\n",
      "Missing from GloVe: else's\n",
      "Missing from GloVe: daughter's\n",
      "Missing from GloVe: bride's\n",
      "Missing from GloVe: blanketa\n",
      "Missing from GloVe: 50's\n",
      "Missing from GloVe: downhillthe\n",
      "Missing from GloVe: boardthe\n",
      "Missing from GloVe: riverthe\n",
      "Missing from GloVe: bypeople\n",
      "Missing from GloVe: elephant's\n",
      "Missing from GloVe: huppe\n",
      "Missing from GloVe: backgroundthe\n",
      "Missing from GloVe: frisbeea\n",
      "Missing from GloVe: restaurant's\n",
      "Missing from GloVe: foodpeople\n",
      "Missing from GloVe: tonight's\n",
      "Missing from GloVe: overheadpeople\n",
      "Missing from GloVe: taylorthe\n",
      "Missing from GloVe: fountaina\n",
      "Missing from GloVe: pink's\n",
      "Missing from GloVe: widea\n",
      "Missing from GloVe: farmers'\n",
      "Missing from GloVe: watermelonsthere\n",
      "Missing from GloVe: fencea\n",
      "Missing from GloVe: gentleman's\n",
      "Missing from GloVe: lay's\n",
      "Missing from GloVe: toolthe\n",
      "Missing from GloVe: aquestrian\n",
      "Missing from GloVe: outdoorsa\n",
      "Missing from GloVe: gamean\n",
      "Missing from GloVe: performance3\n",
      "Missing from GloVe: neighbor's\n",
      "Missing from GloVe: distancea\n",
      "Missing from GloVe: descenda\n",
      "Missing from GloVe: photographthe\n",
      "Missing from GloVe: foreheadthe\n",
      "Missing from GloVe: tattoo's\n",
      "Missing from GloVe: rowboata\n",
      "Missing from GloVe: himselfthe\n",
      "Missing from GloVe: himselfan\n",
      "Missing from GloVe: newspapera\n",
      "Missing from GloVe: rinkthe\n",
      "Missing from GloVe: soocerball\n",
      "Missing from GloVe: stairsa\n",
      "Missing from GloVe: parkthe\n",
      "Missing from GloVe: gallery's\n",
      "Missing from GloVe: racedog\n",
      "Missing from GloVe: stunta\n",
      "Missing from GloVe: read'\n",
      "Missing from GloVe: closed'\n",
      "Missing from GloVe: hiply\n",
      "Missing from GloVe: father's\n",
      "Missing from GloVe: sunglassesa\n",
      "Missing from GloVe: shelter's\n",
      "Missing from GloVe: staresa\n",
      "Missing from GloVe: ballskids\n",
      "Missing from GloVe: riverpeople\n",
      "Missing from GloVe: kitchena\n",
      "Missing from GloVe: dayguy\n",
      "Missing from GloVe: tractora\n",
      "Missing from GloVe: team's\n",
      "Missing from GloVe: labeled'\n",
      "Missing from GloVe: doctor's\n",
      "Missing from GloVe: ocean's\n",
      "Missing from GloVe: obstaclethe\n",
      "Missing from GloVe: equipmenta\n",
      "Missing from GloVe: rifle's\n",
      "Missing from GloVe: mouththe\n",
      "Missing from GloVe: countrytwo\n",
      "Missing from GloVe: countrythe\n",
      "Missing from GloVe: dead'\n",
      "Missing from GloVe: signseveral\n",
      "Missing from GloVe: shirt's\n",
      "Missing from GloVe: icethe\n",
      "Missing from GloVe: kayaka\n",
      "Missing from GloVe: glassesthe\n",
      "Missing from GloVe: drinkingthe\n",
      "Missing from GloVe: circlethe\n",
      "Missing from GloVe: lady's\n",
      "Missing from GloVe: pavitmento\n",
      "Missing from GloVe: word'\n",
      "Missing from GloVe: sex'\n",
      "Missing from GloVe: swinga\n",
      "Missing from GloVe: needlea\n",
      "Missing from GloVe: floora\n",
      "Missing from GloVe: stagethe\n",
      "Missing from GloVe: ponya\n",
      "Missing from GloVe: rink's\n",
      "Missing from GloVe: cakequinn\n",
      "Missing from GloVe: slalomthe\n",
      "Missing from GloVe: wavethree\n",
      "Missing from GloVe: driver's\n",
      "Missing from GloVe: togethera\n",
      "Missing from GloVe: lapsthe\n",
      "Missing from GloVe: floorsome\n",
      "Missing from GloVe: skateboarda\n",
      "Missing from GloVe: athletea\n",
      "Missing from GloVe: paradethe\n",
      "Missing from GloVe: racethere\n",
      "Missing from GloVe: liquidsa\n",
      "Missing from GloVe: submarinethe\n",
      "Missing from GloVe: astroland\n",
      "Missing from GloVe: islandkids\n",
      "Missing from GloVe: walktwo\n",
      "Missing from GloVe: ski's\n",
      "Missing from GloVe: dressa\n",
      "Missing from GloVe: oceanfour\n",
      "Missing from GloVe: sleeding\n",
      "Missing from GloVe: helmeta\n",
      "Missing from GloVe: polesthe\n",
      "Missing from GloVe: roada\n",
      "Missing from GloVe: pike's\n",
      "Missing from GloVe: patrick's\n",
      "Missing from GloVe: trophy's\n",
      "Missing from GloVe: surroundingstwo\n",
      "Missing from GloVe: dogthe\n",
      "Missing from GloVe: peoplethe\n",
      "Missing from GloVe: shopthe\n",
      "Missing from GloVe: son's\n",
      "Missing from GloVe: tracka\n",
      "Missing from GloVe: takena\n",
      "Missing from GloVe: crosswalka\n",
      "Missing from GloVe: bowsa\n",
      "Missing from GloVe: costumea\n",
      "Missing from GloVe: togetherthe\n",
      "Missing from GloVe: hiker's\n",
      "Missing from GloVe: poleshe\n",
      "Missing from GloVe: stumpa\n",
      "Missing from GloVe: wasted'\n",
      "Missing from GloVe: chasseing\n",
      "Missing from GloVe: macbookspeople\n",
      "Missing from GloVe: bting\n",
      "Missing from GloVe: leashthe\n",
      "Missing from GloVe: outstreached\n",
      "Missing from GloVe: churchdecorations\n",
      "Missing from GloVe: lobstera\n",
      "Missing from GloVe: backlegs\n",
      "Missing from GloVe: airthe\n",
      "Missing from GloVe: batter's\n",
      "Missing from GloVe: racedogs\n",
      "Missing from GloVe: outdoorstwo\n",
      "Missing from GloVe: khaki's\n",
      "Missing from GloVe: stepsa\n",
      "Missing from GloVe: luggagethe\n",
      "Missing from GloVe: grayhounds\n",
      "Missing from GloVe: toyskids\n",
      "Missing from GloVe: treethe\n",
      "Missing from GloVe: sandgirls\n",
      "Missing from GloVe: hydranta\n",
      "Missing from GloVe: tilefour\n",
      "Missing from GloVe: biketwo\n",
      "Missing from GloVe: woodsa\n",
      "Missing from GloVe: partypeople\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing from GloVe: logtwo\n",
      "Missing from GloVe: arcadea\n",
      "Missing from GloVe: personthe\n",
      "Missing from GloVe: camerasthe\n",
      "Missing from GloVe: beachtwo\n",
      "Missing from GloVe: gentlemen's'\n",
      "Missing from GloVe: muchthe\n",
      "Missing from GloVe: freesbies\n",
      "Missing from GloVe: boardan\n",
      "Missing from GloVe: sidethree\n",
      "Missing from GloVe: forestthe\n",
      "Missing from GloVe: villagethe\n",
      "Missing from GloVe: couchdog\n",
      "Missing from GloVe: outfita\n",
      "Missing from GloVe: scootera\n",
      "Missing from GloVe: geara\n",
      "Missing from GloVe: staircasepeople\n",
      "Missing from GloVe: kimino\n",
      "Missing from GloVe: hospitala\n",
      "Missing from GloVe: carsa\n",
      "Missing from GloVe: i'll\n",
      "Missing from GloVe: rallya\n",
      "Missing from GloVe: chairsthe\n",
      "Missing from GloVe: alcoholsome\n",
      "Missing from GloVe: runner's\n",
      "Missing from GloVe: seat4\n",
      "Missing from GloVe: jumpthe\n",
      "Missing from GloVe: seidwalk\n",
      "Missing from GloVe: sidewalkthe\n",
      "Missing from GloVe: paintinga\n",
      "Missing from GloVe: somethingsome\n",
      "Missing from GloVe: midairthe\n",
      "Missing from GloVe: telephonea\n",
      "Missing from GloVe: tree's\n",
      "Missing from GloVe: railinga\n",
      "Missing from GloVe: streetwomen\n",
      "Missing from GloVe: tunnela\n",
      "Missing from GloVe: 06pm\n",
      "Missing from GloVe: good's\n",
      "Missing from GloVe: re's\n",
      "Missing from GloVe: stationthere\n",
      "Missing from GloVe: penney's\n",
      "Missing from GloVe: express'\n",
      "Missing from GloVe: shoeshines\n",
      "Missing from GloVe: drawinga\n",
      "Missing from GloVe: headbandsomeone\n",
      "Missing from GloVe: puppiesa\n",
      "Missing from GloVe: settinga\n",
      "Missing from GloVe: snapa\n",
      "Missing from GloVe: skiinga\n",
      "Missing from GloVe: lawnthree\n",
      "Missing from GloVe: drumseveral\n",
      "Missing from GloVe: kayer\n",
      "Missing from GloVe: flowersa\n",
      "Missing from GloVe: cook's\n",
      "Missing from GloVe: handman\n",
      "Missing from GloVe: courta\n",
      "Missing from GloVe: roadpeople\n",
      "Missing from GloVe: bikinia\n",
      "Missing from GloVe: wavethe\n",
      "Missing from GloVe: starbuck's\n",
      "Missing from GloVe: herthe\n",
      "Missing from GloVe: birdsa\n",
      "Missing from GloVe: windowman\n",
      "Missing from GloVe: windowsa\n",
      "Missing from GloVe: basketsan\n",
      "Missing from GloVe: leafsa\n",
      "Missing from GloVe: signedthe\n",
      "Missing from GloVe: murala\n",
      "Missing from GloVe: skisa\n",
      "Missing from GloVe: matchthe\n",
      "Missing from GloVe: city'\n",
      "Missing from GloVe: picturethree\n",
      "Missing from GloVe: courttwo\n",
      "Missing from GloVe: swaetshirt\n",
      "Missing from GloVe: fightingthe\n",
      "Missing from GloVe: tigera\n",
      "Missing from GloVe: raley's\n",
      "Missing from GloVe: handlethe\n",
      "Missing from GloVe: objest\n",
      "Missing from GloVe: alleywaythe\n",
      "Missing from GloVe: ropethe\n",
      "Missing from GloVe: beachchildren\n",
      "Missing from GloVe: meata\n",
      "Missing from GloVe: bencha\n",
      "Missing from GloVe: positiona\n",
      "Missing from GloVe: storepeople\n",
      "Missing from GloVe: venicetwo\n",
      "Missing from GloVe: scooterthe\n",
      "Missing from GloVe: magician's\n",
      "Missing from GloVe: compounda\n",
      "Missing from GloVe: smokingthe\n",
      "Missing from GloVe: tricka\n",
      "Missing from GloVe: magazinea\n",
      "Missing from GloVe: graffited\n",
      "Missing from GloVe: spectatorsthere\n",
      "Missing from GloVe: musiciansa\n",
      "Missing from GloVe: womana\n",
      "Missing from GloVe: derssed\n",
      "Missing from GloVe: haira\n",
      "Missing from GloVe: carnivala\n",
      "Missing from GloVe: jersay\n",
      "Missing from GloVe: clibing\n",
      "Missing from GloVe: bicyclethe\n",
      "Missing from GloVe: someonethe\n",
      "Missing from GloVe: hodling\n",
      "Missing from GloVe: climbingthe\n",
      "Missing from GloVe: shouldera\n",
      "Missing from GloVe: gardeningthe\n",
      "Missing from GloVe: gamekids\n",
      "Missing from GloVe: doorsa\n",
      "Missing from GloVe: weara\n",
      "Missing from GloVe: weartwo\n",
      "Missing from GloVe: wear2\n",
      "Missing from GloVe: partythe\n",
      "Missing from GloVe: zoomsystems\n",
      "Missing from GloVe: shovelthe\n",
      "Missing from GloVe: house's\n",
      "Missing from GloVe: beachthree\n",
      "Missing from GloVe: treesa\n",
      "Missing from GloVe: kakhis\n",
      "Missing from GloVe: bicyclea\n",
      "Missing from GloVe: rinktwo\n",
      "Missing from GloVe: pwople\n",
      "Missing from GloVe: dancingpeople\n",
      "Missing from GloVe: alonea\n",
      "Missing from GloVe: leavesa\n",
      "Missing from GloVe: dogtwo\n",
      "Missing from GloVe: tablean\n",
      "Missing from GloVe: trackhe\n",
      "Missing from GloVe: bikeman\n",
      "Missing from GloVe: uniformman\n",
      "Missing from GloVe: parasailed\n",
      "Missing from GloVe: lockerstwo\n",
      "Missing from GloVe: gametwo\n",
      "Missing from GloVe: studyingthe\n",
      "Missing from GloVe: watersking\n",
      "Missing from GloVe: swimmer's\n",
      "Missing from GloVe: porcha\n",
      "Missing from GloVe: camerasome\n",
      "Missing from GloVe: veststhe\n",
      "Missing from GloVe: watchesa\n",
      "Missing from GloVe: soccertwo\n",
      "Missing from GloVe: sandalsthe\n",
      "Missing from GloVe: dishan\n",
      "Missing from GloVe: housethe\n",
      "Missing from GloVe: bridgeseveral\n",
      "Missing from GloVe: 'two\n",
      "Missing from GloVe: wife's\n",
      "Missing from GloVe: motorcyclea\n",
      "Missing from GloVe: obstaclea\n",
      "Missing from GloVe: wearign\n",
      "Missing from GloVe: hatan\n",
      "Missing from GloVe: countrysomeone\n",
      "Missing from GloVe: signworkers\n",
      "Missing from GloVe: signpeople\n",
      "Missing from GloVe: shortsman\n",
      "Missing from GloVe: sculpturea\n",
      "Missing from GloVe: storesthe\n",
      "Missing from GloVe: escalatorconstruction\n",
      "Missing from GloVe: pajamasthe\n",
      "Missing from GloVe: computera\n",
      "Missing from GloVe: costume2\n",
      "Missing from GloVe: couchthere\n",
      "Missing from GloVe: basketballa\n",
      "Missing from GloVe: backyarda\n",
      "Missing from GloVe: girlfriend's\n",
      "Missing from GloVe: peoplpe\n",
      "Missing from GloVe: yardkids\n",
      "Missing from GloVe: umbrella's\n",
      "Missing from GloVe: night's\n",
      "Missing from GloVe: maybea\n",
      "Missing from GloVe: themthree\n",
      "Missing from GloVe: permeda\n",
      "Missing from GloVe: dresses2\n",
      "Missing from GloVe: microphonethere\n",
      "Missing from GloVe: somebody's\n",
      "Missing from GloVe: penny's\n",
      "Missing from GloVe: school's\n",
      "Missing from GloVe: cornera\n",
      "Missing from GloVe: costumethe\n",
      "Missing from GloVe: runninga\n",
      "Missing from GloVe: wingsthe\n",
      "Missing from GloVe: trackthe\n",
      "Missing from GloVe: benchtwo\n",
      "Missing from GloVe: jacketsthe\n",
      "Missing from GloVe: ornamenta\n",
      "Missing from GloVe: boxthey\n",
      "Missing from GloVe: competeive\n",
      "Missing from GloVe: personshouting\n",
      "Missing from GloVe: rodeothe\n",
      "Missing from GloVe: gamesomeone\n",
      "Missing from GloVe: blanketthe\n",
      "Missing from GloVe: lightthe\n",
      "Missing from GloVe: clubthe\n",
      "Missing from GloVe: computertwo\n",
      "Missing from GloVe: beachthere\n",
      "Missing from GloVe: praciticing\n",
      "Missing from GloVe: causethere\n",
      "Missing from GloVe: sledthe\n",
      "Missing from GloVe: screenthe\n",
      "Missing from GloVe: another's\n",
      "Missing from GloVe: bedthe\n",
      "Missing from GloVe: downhillthere\n",
      "Missing from GloVe: auditoriam\n",
      "Missing from GloVe: citya\n",
      "Missing from GloVe: puddlethe\n",
      "Missing from GloVe: puddlea\n",
      "Missing from GloVe: flightthree\n",
      "Missing from GloVe: lakethe\n",
      "Missing from GloVe: lakeboys\n",
      "Missing from GloVe: splashskilled\n",
      "Missing from GloVe: drumsthe\n",
      "Missing from GloVe: studiothey\n",
      "Missing from GloVe: stadiuma\n",
      "Missing from GloVe: flooda\n",
      "Missing from GloVe: blurrybearded\n",
      "Missing from GloVe: oceantwo\n",
      "Missing from GloVe: babya\n",
      "Missing from GloVe: cyclista\n",
      "Missing from GloVe: tricyclea\n",
      "Missing from GloVe: reenactmentseveral\n",
      "Missing from GloVe: togetherpeople\n",
      "Missing from GloVe: beveragea\n",
      "Missing from GloVe: sinktwo\n",
      "Missing from GloVe: stagethere\n",
      "Missing from GloVe: scrimmagethe\n",
      "Missing from GloVe: seatyoung\n",
      "Missing from GloVe: seatthere\n",
      "Missing from GloVe: childrens'\n",
      "Missing from GloVe: family's\n",
      "Missing from GloVe: arcadethere\n",
      "Missing from GloVe: rocksthe\n",
      "Missing from GloVe: cementa\n",
      "Missing from GloVe: sidewalkthree\n",
      "Missing from GloVe: sidewalkthey\n",
      "Missing from GloVe: sidewalkthere\n",
      "Missing from GloVe: waterfalla\n",
      "Missing from GloVe: coatthe\n",
      "Missing from GloVe: netthe\n",
      "Missing from GloVe: routinethe\n",
      "Missing from GloVe: librarythere\n",
      "Missing from GloVe: walkwaythey\n",
      "Missing from GloVe: violinthe\n",
      "Missing from GloVe: housedogs\n",
      "Missing from GloVe: skateboardthe\n",
      "Missing from GloVe: dcit\n",
      "Missing from GloVe: stauea\n",
      "Missing from GloVe: boyelderly\n",
      "Missing from GloVe: courtyarda\n",
      "Missing from GloVe: snowstormchildren\n",
      "Missing from GloVe: groundthe\n",
      "Missing from GloVe: sweatshirtthe\n",
      "Missing from GloVe: frisbeethe\n",
      "Missing from GloVe: everywhereman\n",
      "Missing from GloVe: brother's\n",
      "Missing from GloVe: jacketa\n",
      "Missing from GloVe: pipemen\n",
      "Missing from GloVe: coverthe\n",
      "Missing from GloVe: fieldsoccer\n",
      "Missing from GloVe: roadthe\n",
      "Missing from GloVe: soccerchildren\n",
      "Missing from GloVe: haven't\n",
      "Missing from GloVe: toythree\n",
      "Missing from GloVe: foodfriends\n",
      "Missing from GloVe: handsa\n",
      "Missing from GloVe: we're\n",
      "Missing from GloVe: ramphalf\n",
      "Missing from GloVe: 70's\n",
      "Missing from GloVe: 80's\n",
      "Missing from GloVe: mountainsman\n",
      "Missing from GloVe: compount\n",
      "Missing from GloVe: umbrellathe\n",
      "Missing from GloVe: gymthe\n",
      "Missing from GloVe: trucka\n",
      "Missing from GloVe: eventgroup\n",
      "Missing from GloVe: firea\n",
      "Missing from GloVe: sunsetthe\n",
      "Missing from GloVe: citypeople\n",
      "Missing from GloVe: texturethe\n",
      "Missing from GloVe: overheada\n",
      "Missing from GloVe: dayseniors\n",
      "Missing from GloVe: opensome\n",
      "Missing from GloVe: paradea\n",
      "Missing from GloVe: wearone\n",
      "Missing from GloVe: leadingsome\n",
      "Missing from GloVe: airhe\n",
      "Missing from GloVe: waterskayakers\n",
      "Missing from GloVe: fabricthe\n",
      "Missing from GloVe: snowtwo\n",
      "Missing from GloVe: hurdlethe\n",
      "Missing from GloVe: polethe\n",
      "Missing from GloVe: terminalthe\n",
      "Missing from GloVe: handsthe\n",
      "Missing from GloVe: racerdirt\n",
      "Missing from GloVe: camerathey\n",
      "Missing from GloVe: camerathere\n",
      "Missing from GloVe: fertilizering\n",
      "Missing from GloVe: harley's\n",
      "Missing from GloVe: watchingt\n",
      "Missing from GloVe: scultupres\n",
      "Missing from GloVe: grafffiti\n",
      "Missing from GloVe: toddler's\n",
      "Missing from GloVe: love's\n",
      "Missing from GloVe: reparied\n",
      "Missing from GloVe: beginners'\n",
      "Missing from GloVe: homcoming\n",
      "Missing from GloVe: cowboys'\n",
      "Missing from GloVe: stanindg\n",
      "Missing from GloVe: dancingdogs\n",
      "Missing from GloVe: alonethe\n",
      "Missing from GloVe: leavestwo\n",
      "Missing from GloVe: ingnue\n",
      "Missing from GloVe: tabletwo\n",
      "Missing from GloVe: poop's\n",
      "Missing from GloVe: trackhuman\n",
      "Missing from GloVe: bikewoman\n",
      "Missing from GloVe: sheherd\n",
      "Missing from GloVe: veterenarian\n",
      "Missing from GloVe: indorrs\n",
      "Missing from GloVe: foundtain\n",
      "Missing from GloVe: patients'\n",
      "Missing from GloVe: performnef\n",
      "Missing from GloVe: doord\n",
      "Missing from GloVe: fieldthree\n",
      "Missing from GloVe: outdoorsan\n",
      "Missing from GloVe: lockersa\n",
      "Missing from GloVe: popeye's\n",
      "Missing from GloVe: strikehumans\n",
      "Missing from GloVe: striketall\n",
      "Missing from GloVe: strikenobody\n",
      "Missing from GloVe: playingthere\n",
      "Missing from GloVe: studyinga\n",
      "Missing from GloVe: daythere\n",
      "Missing from GloVe: whithhis\n",
      "Missing from GloVe: muscicians\n",
      "Missing from GloVe: porchnobody\n",
      "Missing from GloVe: cameraladies\n",
      "Missing from GloVe: weaaring\n",
      "Missing from GloVe: basketballsome\n",
      "Missing from GloVe: basketballbasketball\n",
      "Missing from GloVe: basketballthe\n",
      "Missing from GloVe: shop's\n",
      "Missing from GloVe: weras\n",
      "Missing from GloVe: wairs\n",
      "Missing from GloVe: vestspeople\n",
      "Missing from GloVe: tentthere\n",
      "Missing from GloVe: himselfno\n",
      "Missing from GloVe: himselfrasputin\n",
      "Missing from GloVe: scark\n",
      "Missing from GloVe: stickthrower\n",
      "Missing from GloVe: hrose\n",
      "Missing from GloVe: watchold\n",
      "Missing from GloVe: watchhumans\n",
      "Missing from GloVe: watchparents\n",
      "Missing from GloVe: ocaen\n",
      "Missing from GloVe: applebee's\n",
      "Missing from GloVe: barber's\n",
      "Missing from GloVe: buildingshadows\n",
      "Missing from GloVe: greyhouds\n",
      "Missing from GloVe: twilring\n",
      "Missing from GloVe: watchesthe\n",
      "Missing from GloVe: aduts\n",
      "Missing from GloVe: drilldaffy\n",
      "Missing from GloVe: drillthe\n",
      "Missing from GloVe: drilla\n",
      "Missing from GloVe: pankcake\n",
      "Missing from GloVe: racemen\n",
      "Missing from GloVe: racemale\n",
      "Missing from GloVe: partarke\n",
      "Missing from GloVe: yelliing\n",
      "Missing from GloVe: socceran\n",
      "Missing from GloVe: balltwo\n",
      "Missing from GloVe: vagner\n",
      "Missing from GloVe: bincoculars\n",
      "Missing from GloVe: sandalsa\n",
      "Missing from GloVe: couhc\n",
      "Missing from GloVe: streetgame\n",
      "Missing from GloVe: telescopeman\n",
      "Missing from GloVe: romaticly\n",
      "Missing from GloVe: dishsharing\n",
      "Missing from GloVe: crashorange\n",
      "Missing from GloVe: crasheveryone\n",
      "Missing from GloVe: crashthe\n",
      "Missing from GloVe: crashyou\n",
      "Missing from GloVe: crashthere\n",
      "Missing from GloVe: crashan\n",
      "Missing from GloVe: housethere\n",
      "Missing from GloVe: happeningo\n",
      "Missing from GloVe: wigit\n",
      "Missing from GloVe: wigevery\n",
      "Missing from GloVe: wigthe\n",
      "Missing from GloVe: bridgeparents\n",
      "Missing from GloVe: turntwo\n",
      "Missing from GloVe: eneds\n",
      "Missing from GloVe: upthey\n",
      "Missing from GloVe: motorcylists\n",
      "Missing from GloVe: juliett\n",
      "Missing from GloVe: 'men\n",
      "Missing from GloVe: scuplting\n",
      "Missing from GloVe: motorcyclemotorcycle\n",
      "Missing from GloVe: windowthree\n",
      "Missing from GloVe: racquetan\n",
      "Missing from GloVe: playinhg\n",
      "Missing from GloVe: handband\n",
      "Missing from GloVe: grandparent's\n",
      "Missing from GloVe: pillos\n",
      "Missing from GloVe: isplaying\n",
      "Missing from GloVe: countrytrains\n",
      "Missing from GloVe: swimmign\n",
      "Missing from GloVe: richshaw\n",
      "Missing from GloVe: signthere\n",
      "Missing from GloVe: signtwo\n",
      "Missing from GloVe: signconstruction\n",
      "Missing from GloVe: streetshe\n",
      "Missing from GloVe: shortsa\n",
      "Missing from GloVe: inred\n",
      "Missing from GloVe: sculpturean\n",
      "Missing from GloVe: storesa\n",
      "Missing from GloVe: weinging\n",
      "Missing from GloVe: deskseveral\n",
      "Missing from GloVe: deskpeople\n",
      "Missing from GloVe: deskthe\n",
      "Missing from GloVe: stagean\n",
      "Missing from GloVe: company's\n",
      "Missing from GloVe: swordsman's\n",
      "Missing from GloVe: sowrdsman\n",
      "Missing from GloVe: handrials\n",
      "Missing from GloVe: daddy's\n",
      "Missing from GloVe: escalatorworkers\n",
      "Missing from GloVe: pajamasa\n",
      "Missing from GloVe: apcolypse\n",
      "Missing from GloVe: computerthere\n",
      "Missing from GloVe: sisterschildren\n",
      "Missing from GloVe: sistersa\n",
      "Missing from GloVe: sisterswoman\n",
      "Missing from GloVe: comtemplates\n",
      "Missing from GloVe: marketwomen\n",
      "Missing from GloVe: shirta\n",
      "Missing from GloVe: shirtthe\n",
      "Missing from GloVe: shirtsomeone\n",
      "Missing from GloVe: de'\n",
      "Missing from GloVe: rcowd\n",
      "Missing from GloVe: announcer's\n",
      "Missing from GloVe: costume3\n",
      "Missing from GloVe: basketballthree\n",
      "Missing from GloVe: backyardan\n",
      "Missing from GloVe: subwaythey\n",
      "Missing from GloVe: subwayhe\n",
      "Missing from GloVe: subwaythe\n",
      "Missing from GloVe: exchaning\n",
      "Missing from GloVe: wriring\n",
      "Missing from GloVe: occasssion\n",
      "Missing from GloVe: picturethere\n",
      "Missing from GloVe: contsruction\n",
      "Missing from GloVe: qu'ran\n",
      "Missing from GloVe: stree5t\n",
      "Missing from GloVe: kssing\n",
      "Missing from GloVe: 1960's\n",
      "Missing from GloVe: tickiling\n",
      "Missing from GloVe: yardthere\n",
      "Missing from GloVe: hydraphobic\n",
      "Missing from GloVe: stadiumstadium\n",
      "Missing from GloVe: stadiumthere's\n",
      "Missing from GloVe: stadiumsomething\n",
      "Missing from GloVe: grrom\n",
      "Missing from GloVe: streetthey\n",
      "Missing from GloVe: sitts\n",
      "Missing from GloVe: skotch\n",
      "Missing from GloVe: backgroundnobody\n",
      "Missing from GloVe: bannner\n",
      "Missing from GloVe: maybean\n",
      "Missing from GloVe: classroomm\n",
      "Missing from GloVe: themdogs\n",
      "Missing from GloVe: treeyoung\n",
      "Missing from GloVe: treekids\n",
      "Missing from GloVe: treeadults\n",
      "Missing from GloVe: wateran\n",
      "Missing from GloVe: wateradults\n",
      "Missing from GloVe: female's\n",
      "Missing from GloVe: sleepingc\n",
      "Missing from GloVe: permedthe\n",
      "Missing from GloVe: scaffoldingeveryone\n",
      "Missing from GloVe: scaffoldingthey\n",
      "Missing from GloVe: scaffoldingpeople\n",
      "Missing from GloVe: gunchild\n",
      "Missing from GloVe: gunkids\n",
      "Missing from GloVe: poterry\n",
      "Missing from GloVe: dressesthe\n",
      "Missing from GloVe: itemsa\n",
      "Missing from GloVe: itemsthree\n",
      "Missing from GloVe: itemschildren\n",
      "Missing from GloVe: college's\n",
      "Missing from GloVe: rodeohorseback\n",
      "Missing from GloVe: single's\n",
      "Missing from GloVe: suglasses\n",
      "Missing from GloVe: cornertwo\n",
      "Missing from GloVe: hulahooping\n",
      "Missing from GloVe: costumethere\n",
      "Missing from GloVe: beltthe\n",
      "Missing from GloVe: beltpeople\n",
      "Missing from GloVe: runningpup\n",
      "Missing from GloVe: spelunks\n",
      "Missing from GloVe: dctors\n",
      "Missing from GloVe: cameraan\n",
      "Missing from GloVe: parks'\n",
      "Missing from GloVe: candlee\n",
      "Missing from GloVe: dreesed\n",
      "Missing from GloVe: weren't\n",
      "Missing from GloVe: anoterh\n",
      "Missing from GloVe: wingsa\n",
      "Missing from GloVe: trackanimals\n",
      "Missing from GloVe: videohraphers\n",
      "Missing from GloVe: benchthree\n",
      "Missing from GloVe: bachelor's\n",
      "Missing from GloVe: snine\n",
      "Missing from GloVe: 1970's\n",
      "Missing from GloVe: trashmore\n",
      "Missing from GloVe: wearinh\n",
      "Missing from GloVe: paradesome\n",
      "Missing from GloVe: referee's\n",
      "Missing from GloVe: forumating\n",
      "Missing from GloVe: brownb\n",
      "Missing from GloVe: checmical\n",
      "Missing from GloVe: jacketsthere\n",
      "Missing from GloVe: telescoper\n",
      "Missing from GloVe: standinig\n",
      "Missing from GloVe: ornamenttwo\n",
      "Missing from GloVe: eachother's\n",
      "Missing from GloVe: boxthere\n",
      "Missing from GloVe: relationaship\n",
      "Missing from GloVe: litered\n",
      "Missing from GloVe: personsleeping\n",
      "Missing from GloVe: rodeocowboys\n",
      "Missing from GloVe: gamegoing\n",
      "Missing from GloVe: grandchild's\n",
      "Missing from GloVe: morotcycle\n",
      "Missing from GloVe: idditarod\n",
      "Missing from GloVe: lightthere\n",
      "Missing from GloVe: clubhe\n",
      "Missing from GloVe: windsufring\n",
      "Missing from GloVe: 'mega\n",
      "Missing from GloVe: pj's\n",
      "Missing from GloVe: jouls\n",
      "Missing from GloVe: olymipic\n",
      "Missing from GloVe: computerthe\n",
      "Missing from GloVe: zebra's\n",
      "Missing from GloVe: peocock\n",
      "Missing from GloVe: york's\n",
      "Missing from GloVe: demonstator\n",
      "Missing from GloVe: luggle\n",
      "Missing from GloVe: shakespeare's\n",
      "Missing from GloVe: ollivanders\n",
      "Missing from GloVe: trackan\n",
      "Missing from GloVe: swingthere\n",
      "Missing from GloVe: jacket's\n",
      "Missing from GloVe: bicycles'\n",
      "Missing from GloVe: station's\n",
      "Missing from GloVe: webelo\n",
      "Missing from GloVe: foodthere\n",
      "Missing from GloVe: togetherthere\n",
      "Missing from GloVe: togetherone\n",
      "Missing from GloVe: areathey\n",
      "Missing from GloVe: skting\n",
      "Missing from GloVe: causethe\n",
      "Missing from GloVe: listeining\n",
      "Missing from GloVe: leo's\n",
      "Missing from GloVe: stuntsthis\n",
      "Missing from GloVe: stuntsabe\n",
      "Missing from GloVe: stuntsa\n",
      "Missing from GloVe: stronginthearm\n",
      "Missing from GloVe: sculting\n",
      "Missing from GloVe: artskater\n",
      "Missing from GloVe: umbralla\n",
      "Missing from GloVe: ricb\n",
      "Missing from GloVe: globetrotter's\n",
      "Missing from GloVe: underrclithes\n",
      "Missing from GloVe: eventthe\n",
      "Missing from GloVe: eventthere\n",
      "Missing from GloVe: tubeschildren\n",
      "Missing from GloVe: tubesmen\n",
      "Missing from GloVe: tubesboys\n",
      "Missing from GloVe: pflying\n",
      "Missing from GloVe: sledtwo\n",
      "Missing from GloVe: microsopic\n",
      "Missing from GloVe: wwalking\n",
      "Missing from GloVe: besdie\n",
      "Missing from GloVe: volelyball\n",
      "Missing from GloVe: nun's\n",
      "Missing from GloVe: lpayers\n",
      "Missing from GloVe: ridingman\n",
      "Missing from GloVe: ridinga\n",
      "Missing from GloVe: airthere\n",
      "Missing from GloVe: screena\n",
      "Missing from GloVe: church's\n",
      "Missing from GloVe: marathan\n",
      "Missing from GloVe: grassan\n",
      "Missing from GloVe: acrobat's\n",
      "Missing from GloVe: trackgreyhounds\n",
      "Missing from GloVe: trackcanines\n",
      "Missing from GloVe: grassit's\n",
      "Missing from GloVe: patient's\n",
      "Missing from GloVe: flooreveryone\n",
      "Missing from GloVe: floorthe\n",
      "Missing from GloVe: floorthere\n",
      "Missing from GloVe: parashutes\n",
      "Missing from GloVe: earth's\n",
      "Missing from GloVe: bedthere\n",
      "Missing from GloVe: foothpath\n",
      "Missing from GloVe: downhillsomeone\n",
      "Missing from GloVe: pattleboating\n",
      "Missing from GloVe: sttands\n",
      "Missing from GloVe: acnhored\n",
      "Missing from GloVe: trambled\n",
      "Missing from GloVe: interpertive\n",
      "Missing from GloVe: citythe\n",
      "Missing from GloVe: perot's\n",
      "Missing from GloVe: flirtng\n",
      "Missing from GloVe: wiedling\n",
      "Missing from GloVe: flightthey\n",
      "Missing from GloVe: lakethere\n",
      "Missing from GloVe: guggling\n",
      "Missing from GloVe: figherfighers\n",
      "Missing from GloVe: watchnot\n",
      "Missing from GloVe: won't\n",
      "Missing from GloVe: splashswimmers\n",
      "Missing from GloVe: vigirously\n",
      "Missing from GloVe: eminem's\n",
      "Missing from GloVe: bikethis\n",
      "Missing from GloVe: mountina\n",
      "Missing from GloVe: drumsa\n",
      "Missing from GloVe: togethertwo\n",
      "Missing from GloVe: male's\n",
      "Missing from GloVe: ocnea\n",
      "Missing from GloVe: ittwo\n",
      "Missing from GloVe: itthere\n",
      "Missing from GloVe: studiothis\n",
      "Missing from GloVe: desolete\n",
      "Missing from GloVe: stadiumtwo\n",
      "Missing from GloVe: oerson\n",
      "Missing from GloVe: consisitng\n",
      "Missing from GloVe: beachgoing\n",
      "Missing from GloVe: floodthere\n",
      "Missing from GloVe: blurrysad\n",
      "Missing from GloVe: maktes\n",
      "Missing from GloVe: winab\n",
      "Missing from GloVe: stabds\n",
      "Missing from GloVe: chairthe\n",
      "Missing from GloVe: poolgirls\n",
      "Missing from GloVe: poolwomen's\n",
      "Missing from GloVe: poolin\n",
      "Missing from GloVe: babytwo\n",
      "Missing from GloVe: abowl\n",
      "Missing from GloVe: motorbik\n",
      "Missing from GloVe: twom\n",
      "Missing from GloVe: boardthere\n",
      "Missing from GloVe: cyclistthere\n",
      "Missing from GloVe: greenry\n",
      "Missing from GloVe: jocket\n",
      "Missing from GloVe: tpicture\n",
      "Missing from GloVe: bear's\n",
      "Missing from GloVe: tricyclethe\n",
      "Missing from GloVe: onnobody\n",
      "Missing from GloVe: pointign\n",
      "Missing from GloVe: overtwo\n",
      "Missing from GloVe: overfor\n",
      "Missing from GloVe: puddlein\n",
      "Missing from GloVe: puddlesisters\n",
      "Missing from GloVe: anthers'\n",
      "Missing from GloVe: expirament\n",
      "Missing from GloVe: pursuiting\n",
      "Missing from GloVe: renasance\n",
      "Missing from GloVe: oldly\n",
      "Missing from GloVe: sidewalkseveral\n",
      "Missing from GloVe: walkds\n",
      "Missing from GloVe: reenactmenta\n",
      "Missing from GloVe: kris'\n",
      "Missing from GloVe: yardsaling\n",
      "Missing from GloVe: togetherwomen\n",
      "Missing from GloVe: beverageeveryone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing from GloVe: mom's\n",
      "Missing from GloVe: 1980's\n",
      "Missing from GloVe: sinkboy\n",
      "Missing from GloVe: stagethey\n",
      "Missing from GloVe: watchingthere\n",
      "Missing from GloVe: watchingtoday's\n",
      "Missing from GloVe: watchingthe\n",
      "Missing from GloVe: scrimmagethere\n",
      "Missing from GloVe: taekondo\n",
      "Missing from GloVe: princecess\n",
      "Missing from GloVe: 40's\n",
      "Missing from GloVe: structurethe\n",
      "Missing from GloVe: structurethere\n",
      "Missing from GloVe: structurechildren\n",
      "Missing from GloVe: seatsome\n",
      "Missing from GloVe: seatwomen\n",
      "Missing from GloVe: seatsullen\n",
      "Missing from GloVe: themtwo\n",
      "Missing from GloVe: otuside\n",
      "Missing from GloVe: cat's\n",
      "Missing from GloVe: spelunkersthe\n",
      "Missing from GloVe: spelunkersthree\n",
      "Missing from GloVe: spelunkersa\n",
      "Missing from GloVe: fireworkspeople\n",
      "Missing from GloVe: fireworkssad\n",
      "Missing from GloVe: fireworksdogs\n",
      "Missing from GloVe: sidewalkpeople\n",
      "Missing from GloVe: arcadethe\n",
      "Missing from GloVe: quarterback's\n",
      "Missing from GloVe: year's\n",
      "Missing from GloVe: cementi\n",
      "Missing from GloVe: cjild\n",
      "Missing from GloVe: bymen\n",
      "Missing from GloVe: byeveryone\n",
      "Missing from GloVe: pavenment\n",
      "Missing from GloVe: hertwo\n",
      "Missing from GloVe: lighthouse's\n",
      "Missing from GloVe: sidewalke\n",
      "Missing from GloVe: sidewalkat\n",
      "Missing from GloVe: pipea\n",
      "Missing from GloVe: waterfallthere\n",
      "Missing from GloVe: poletall\n",
      "Missing from GloVe: polenobody\n",
      "Missing from GloVe: polesome\n",
      "Missing from GloVe: claranet\n",
      "Missing from GloVe: grouns\n",
      "Missing from GloVe: coata\n",
      "Missing from GloVe: ggrass\n",
      "Missing from GloVe: stationa\n",
      "Missing from GloVe: mountain's\n",
      "Missing from GloVe: home's\n",
      "Missing from GloVe: daytwo\n",
      "Missing from GloVe: routinepeople\n",
      "Missing from GloVe: playsnickelback\n",
      "Missing from GloVe: playsthere\n",
      "Missing from GloVe: playsavril\n",
      "Missing from GloVe: ebach\n",
      "Missing from GloVe: librarythe\n",
      "Missing from GloVe: walkwaythere\n",
      "Missing from GloVe: violina\n",
      "Missing from GloVe: swaeting\n",
      "Missing from GloVe: tounrament\n",
      "Missing from GloVe: rifing\n",
      "Missing from GloVe: shoeshining\n",
      "Missing from GloVe: shoeshiners\n",
      "Missing from GloVe: houseanimals\n",
      "Missing from GloVe: drivies\n",
      "Missing from GloVe: tagscould\n",
      "Missing from GloVe: tagsappears\n",
      "Missing from GloVe: tagsthe\n",
      "Missing from GloVe: skateboardthere\n",
      "Missing from GloVe: dcthe\n",
      "Missing from GloVe: wallthere's\n",
      "Missing from GloVe: stauenobody\n",
      "Missing from GloVe: farm's\n",
      "Missing from GloVe: boythe\n",
      "Missing from GloVe: landmill\n",
      "Missing from GloVe: carthere\n",
      "Missing from GloVe: hilltwo\n",
      "Missing from GloVe: play's\n",
      "Missing from GloVe: windowtwo\n",
      "Missing from GloVe: cousin's\n",
      "Missing from GloVe: pnacho\n",
      "Missing from GloVe: vehiclesa\n",
      "Missing from GloVe: vehiclesthe\n",
      "Missing from GloVe: vehiclesno\n",
      "Missing from GloVe: playingbag\n",
      "Missing from GloVe: valentine's\n",
      "Missing from GloVe: courtyardbikers\n",
      "Missing from GloVe: clothees\n",
      "Missing from GloVe: snowstorma\n",
      "Missing from GloVe: groundthey\n",
      "Missing from GloVe: sweatshirtthere\n",
      "Missing from GloVe: clairnet\n",
      "Missing from GloVe: yardan\n",
      "Missing from GloVe: odn't\n",
      "Missing from GloVe: it'll\n",
      "Missing from GloVe: areathere\n",
      "Missing from GloVe: itgirl\n",
      "Missing from GloVe: itsad\n",
      "Missing from GloVe: itperson\n",
      "Missing from GloVe: speinding\n",
      "Missing from GloVe: everywherea\n",
      "Missing from GloVe: waternobody\n",
      "Missing from GloVe: chirldern\n",
      "Missing from GloVe: jacketprofessional\n",
      "Missing from GloVe: pipethugs\n",
      "Missing from GloVe: protectnig\n",
      "Missing from GloVe: deleivering\n",
      "Missing from GloVe: cocach\n",
      "Missing from GloVe: caot\n",
      "Missing from GloVe: peroccupied\n",
      "Missing from GloVe: performer's\n",
      "Missing from GloVe: photograhper\n",
      "Missing from GloVe: jobpeople\n",
      "Missing from GloVe: jobworkers\n",
      "Missing from GloVe: trumbone\n",
      "Missing from GloVe: coversome\n",
      "Missing from GloVe: fieldbaseball\n",
      "Missing from GloVe: graffitit\n",
      "Missing from GloVe: carrriages\n",
      "Missing from GloVe: graffti\n",
      "Missing from GloVe: roadhe\n",
      "Missing from GloVe: ptient\n",
      "Missing from GloVe: celebratinng\n",
      "Missing from GloVe: kickflipping\n",
      "Missing from GloVe: altheltes\n",
      "Missing from GloVe: vvehicle\n",
      "Missing from GloVe: splots\n",
      "Missing from GloVe: concertthe\n",
      "Missing from GloVe: setthere\n",
      "Missing from GloVe: soccerkids\n",
      "Missing from GloVe: riverthere\n",
      "Missing from GloVe: ewater\n",
      "Missing from GloVe: cheese's\n",
      "Missing from GloVe: coutnries'\n",
      "Missing from GloVe: proffesoinal\n",
      "Missing from GloVe: toyone\n",
      "Missing from GloVe: macarana\n",
      "Missing from GloVe: competitionhorses\n",
      "Missing from GloVe: competitiontwo\n",
      "Missing from GloVe: competitionthey\n",
      "Missing from GloVe: streetbutterflies\n",
      "Missing from GloVe: streetpeople\n",
      "Missing from GloVe: handsi\n",
      "Missing from GloVe: couldn't\n",
      "Missing from GloVe: sidewalkan\n",
      "Missing from GloVe: bucycle\n",
      "Missing from GloVe: bungeeing\n",
      "Missing from GloVe: beachlittle\n",
      "Missing from GloVe: feltch\n",
      "Missing from GloVe: alleywaythere\n",
      "Missing from GloVe: cnducting\n",
      "Missing from GloVe: rampeight\n",
      "Missing from GloVe: fieldthere\n",
      "Missing from GloVe: twin's\n",
      "Missing from GloVe: picture's\n",
      "Missing from GloVe: rusy\n",
      "Missing from GloVe: perairs\n",
      "Missing from GloVe: colthed\n",
      "Missing from GloVe: boss'\n",
      "Missing from GloVe: mountainsred\n",
      "Missing from GloVe: repaied\n",
      "Missing from GloVe: bvoy\n",
      "Missing from GloVe: labworker\n",
      "Missing from GloVe: onlittle\n",
      "Missing from GloVe: camerasomeone\n",
      "Missing from GloVe: cathers\n",
      "Missing from GloVe: beloging\n",
      "Missing from GloVe: frisbess\n",
      "Missing from GloVe: umbrellathere\n",
      "Missing from GloVe: colidascope\n",
      "Missing from GloVe: telescopethe\n",
      "Missing from GloVe: gymthree\n",
      "Missing from GloVe: prdestian\n",
      "Missing from GloVe: pigieons\n",
      "Missing from GloVe: vehicle's\n",
      "Missing from GloVe: stnding\n",
      "Missing from GloVe: oreiental\n",
      "Missing from GloVe: truncks\n",
      "Missing from GloVe: truckan\n",
      "Missing from GloVe: eventpeople\n",
      "Missing from GloVe: firean\n",
      "Missing from GloVe: sunsetthere\n",
      "Missing from GloVe: passersbys\n",
      "Missing from GloVe: emptyin\n",
      "Missing from GloVe: hillthere\n",
      "Missing from GloVe: soccersome\n",
      "Missing from GloVe: soccera\n",
      "Missing from GloVe: soccerlittle\n",
      "Missing from GloVe: herpeople\n",
      "Missing from GloVe: goaltends\n",
      "Missing from GloVe: manastary\n",
      "Missing from GloVe: marathone\n",
      "Missing from GloVe: zuul\n",
      "Missing from GloVe: etaing\n",
      "Missing from GloVe: commentatning\n",
      "Missing from GloVe: staniding\n",
      "Missing from GloVe: outdorrs\n",
      "Missing from GloVe: bike's\n",
      "Missing from GloVe: smilingsomeone\n",
      "Missing from GloVe: skatebaord\n",
      "Missing from GloVe: ridiing\n",
      "Missing from GloVe: citycase\n",
      "Missing from GloVe: outddors\n",
      "Missing from GloVe: smilefruits\n",
      "Missing from GloVe: sunbeathing\n",
      "Missing from GloVe: texturetwo\n",
      "Missing from GloVe: horu\n",
      "Missing from GloVe: overheadone\n",
      "Missing from GloVe: overheadthe\n",
      "Missing from GloVe: indide\n",
      "Missing from GloVe: rehearsaling\n",
      "Missing from GloVe: singer's\n",
      "Missing from GloVe: wayne's\n",
      "Missing from GloVe: bansy\n",
      "Missing from GloVe: marathron\n",
      "Missing from GloVe: buildingan\n",
      "Missing from GloVe: openpeople\n",
      "Missing from GloVe: enjying\n",
      "Missing from GloVe: skatesboards\n",
      "Missing from GloVe: spray's\n",
      "Missing from GloVe: slappign\n",
      "Missing from GloVe: wearweddings\n",
      "Missing from GloVe: weargay\n",
      "Missing from GloVe: wearboth\n",
      "Missing from GloVe: wearit\n",
      "Missing from GloVe: leadinga\n",
      "Missing from GloVe: waterspeople\n",
      "Missing from GloVe: hopskotch\n",
      "Missing from GloVe: snowthe\n",
      "Missing from GloVe: vendor's\n",
      "Missing from GloVe: kleets\n",
      "Missing from GloVe: hurdlea\n",
      "Missing from GloVe: cruilty\n",
      "Missing from GloVe: polethere\n",
      "Missing from GloVe: woodsthere\n",
      "Missing from GloVe: woodsthis\n",
      "Missing from GloVe: woodspeople\n",
      "Missing from GloVe: terminalthere\n",
      "Missing from GloVe: swinn\n",
      "Missing from GloVe: vicar's\n",
      "Missing from GloVe: handsthere\n",
      "Missing from GloVe: liquidone\n",
      "Missing from GloVe: inntertube\n",
      "Missing from GloVe: racera\n",
      "Missing from GloVe: watchingan\n",
      "Missing from GloVe: watersome\n",
      "Missing from GloVe: lickes\n"
     ]
    }
   ],
   "source": [
    "# create embedding matrix \n",
    "GLOVE_STORE = 'precomputed_glove_weights_shortened'\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size+1, embedding_hidden_size)) #(39832, 300)\n",
    "for word, id_ in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word) #embedding_vector.shape - (300,)\n",
    "    if embedding_vector is not None: # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[id_] = embedding_vector\n",
    "    else:\n",
    "        print('Missing from GloVe: {}'.format(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cheap-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(GLOVE_STORE, embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-selection",
   "metadata": {},
   "source": [
    "##### If there is processed glove embedding matrix in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sixth-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_STORE = 'precomputed_glove_weights_shortened'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "talented-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(GLOVE_STORE + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cordless-sacramento",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13013, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "subject-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, concatenate, BatchNormalization, Input, Dense, Embedding, Bidirectional, Dropout, Attention, TimeDistributed, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-anthropology",
   "metadata": {},
   "source": [
    "### LSTM (concatenation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "virgin-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = Input(shape=(max_length,), dtype='int32')\n",
    "hypothesis = Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "premise2 = Embedding(vocab_size+1, \n",
    "                     embedding_hidden_size, \n",
    "                     weights=[embedding_matrix], \n",
    "                     input_length=max_length, \n",
    "                     trainable=False)(premise)\n",
    "hypothesis2 = Embedding(vocab_size+1, \n",
    "                     embedding_hidden_size, \n",
    "                     weights=[embedding_matrix], \n",
    "                     input_length=max_length, \n",
    "                     trainable=False)(hypothesis)\n",
    "\n",
    "premise3 = Dense(units=embedding_hidden_size, \n",
    "                 activation=activation_function)(premise2)\n",
    "hypothesis3 = Dense(units=embedding_hidden_size, \n",
    "                    activation=activation_function)(hypothesis2)\n",
    "\n",
    "premise4 = LSTM(units=embedding_hidden_size, \n",
    "                dropout=dropout_lstm)(premise3)\n",
    "hypothesis4 = LSTM(units=embedding_hidden_size, \n",
    "                   dropout=dropout_lstm)(hypothesis3)\n",
    "\n",
    "premise5 = BatchNormalization()(premise4)\n",
    "hypothesis5 = BatchNormalization()(hypothesis4)\n",
    "\n",
    "joint = concatenate([premise5, hypothesis5], axis=1)\n",
    "joint = Dropout(dropout_rate)(joint)\n",
    "\n",
    "#####\n",
    "#for i in range(3):\n",
    "    #print(i)\n",
    "    #joint = joined_dense_layer(joint)\n",
    "    #joint = dropout_layer(joint)\n",
    "    #joint = batch_normalization(joint)\n",
    "\n",
    "####\n",
    "\n",
    "pred = Dense(units=n_labels, \n",
    "             activation=\"softmax\")(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "threaded-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 152, 300)     3903900     input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 152, 300)     3903900     input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 152, 300)     90300       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 152, 300)     90300       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 300)          721200      dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 300)          721200      dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 300)          1200        lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 300)          1200        lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 600)          0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 600)          0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 3)            1803        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 9,435,003\n",
      "Trainable params: 1,626,003\n",
      "Non-trainable params: 7,809,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[premise, hypothesis], outputs=pred) \n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "brilliant-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "appointed-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45948, 152)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prem_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "twenty-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "45948/45948 [==============================] - 6805s 148ms/step - loss: 1.0986 - accuracy: 0.3345\n",
      "\n",
      "Epoch 00001: saving model to training_2/cp.ckpt\n",
      "Epoch 2/2\n",
      "45948/45948 [==============================] - 7294s 159ms/step - loss: 1.0986 - accuracy: 0.3373\n",
      "\n",
      "Epoch 00002: saving model to training_2/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb950c83d0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train_prem_encoded, train_hyp_encoded], \n",
    "          y=train_labels, \n",
    "          batch_size=batch_size,\n",
    "          epochs=2, \n",
    "          verbose=1, \n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually save weights\n",
    "path = 'checkpoints/lstm_training1'\n",
    "model.save_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading from checkpoints\n",
    "model = create_model()\n",
    "model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "harmful-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45948, 152)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prem_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "chicken-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9842/9842 [==============================] - 164s 17ms/step - loss: 1.0986 - accuracy: 0.3331\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([dev_prem_encoded, dev_hyp_encoded], dev_labels, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "spread-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.098552942276001\n",
      "0.33306238055229187\n"
     ]
    }
   ],
   "source": [
    "# epochs = 2\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-storm",
   "metadata": {},
   "source": [
    "### Sum Embeddings (Concatenation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "disabled-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, concatenate, BatchNormalization, Input, Dense, Embedding, Bidirectional, Dropout, Attention, TimeDistributed, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "olive-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = Input(shape=(max_length,), dtype='int32')\n",
    "hypothesis = Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "premise2 = Embedding(vocab_size+1, \n",
    "                     embedding_hidden_size, \n",
    "                     weights=[embedding_matrix], \n",
    "                     input_length=max_length, \n",
    "                     trainable=False)(premise)\n",
    "hypothesis2 = Embedding(vocab_size+1, \n",
    "                     embedding_hidden_size, \n",
    "                     weights=[embedding_matrix], \n",
    "                     input_length=max_length, \n",
    "                     trainable=False)(hypothesis)\n",
    "\n",
    "premise3 = Dense(units=embedding_hidden_size, \n",
    "                 activation=activation_function)(premise2)\n",
    "hypothesis3 = Dense(units=embedding_hidden_size, \n",
    "                    activation=activation_function)(hypothesis2)\n",
    "\n",
    "premise4 = Lambda(lambda x: tf.keras.backend.sum(x, axis=1, keepdims=False), \n",
    "                  output_shape=(embedding_hidden_size,))(premise3)\n",
    "hypothesis4 = Lambda(lambda x: tf.keras.backend.sum(x, axis=1, keepdims=False), \n",
    "                     output_shape=(embedding_hidden_size,))(hypothesis3)\n",
    "\n",
    "premise5 = BatchNormalization()(premise4)\n",
    "hypothesis5 = BatchNormalization()(hypothesis4)\n",
    "\n",
    "joint = concatenate([premise5, hypothesis5], axis=1)\n",
    "joint = Dropout(dropout_rate)(joint)\n",
    "\n",
    "#####\n",
    "#for i in range(3):\n",
    "    #print(i)\n",
    "    #joint = joined_dense_layer(joint)\n",
    "    #joint = dropout_layer(joint)\n",
    "    #joint = batch_normalization(joint)\n",
    "\n",
    "####\n",
    "\n",
    "pred = Dense(units=n_labels, \n",
    "             activation=\"softmax\")(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "furnished-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 152, 300)     3903900     input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 152, 300)     3903900     input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 152, 300)     90300       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 152, 300)     90300       embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 300)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 300)          0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 300)          1200        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 300)          1200        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 600)          0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 600)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 3)            1803        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,992,603\n",
      "Trainable params: 183,603\n",
      "Non-trainable params: 7,809,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sum_embeddings = Model(inputs=[premise, hypothesis], \n",
    "                             outputs=pred) \n",
    "model_sum_embeddings.compile(optimizer=optimizer, \n",
    "                             loss='sparse_categorical_crossentropy', \n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "model_sum_embeddings.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "biblical-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_path = \"training_3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "productive-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "45948/45948 [==============================] - 77s 2ms/step - loss: 1.0986 - accuracy: 0.3324\n",
      "\n",
      "Epoch 00001: saving model to training_3/cp.ckpt\n",
      "Epoch 2/2\n",
      "45948/45948 [==============================] - 80s 2ms/step - loss: 1.0986 - accuracy: 0.3277 0s - loss: 1.0986 - accuracy: 0.32\n",
      "\n",
      "Epoch 00002: saving model to training_3/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7febae2db4f0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sum_embeddings.fit(x=[train_prem_encoded, train_hyp_encoded], \n",
    "                         y=train_labels, \n",
    "                         batch_size=batch_size,\n",
    "                         epochs=2, \n",
    "                         verbose=1, \n",
    "                         callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "middle-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9842/9842 [==============================] - 10s 988us/step - loss: 31.6682 - accuracy: 0.3657\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_sum_embeddings.evaluate([dev_prem_encoded, dev_hyp_encoded], dev_labels, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "extraordinary-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.668176651000977\n",
      "0.36567771434783936\n"
     ]
    }
   ],
   "source": [
    "# sum_embeddings, epochs = 2\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "spectacular-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "#from keras.utils import plot_model plot_model(model, to_file='model.png')\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model_sum_embeddings, to_file='model.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-brake",
   "metadata": {},
   "source": [
    "### Conneau et al. 3 matching methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "secure-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, concatenate, BatchNormalization, Input, Dense, Embedding, Dropout, Attention, TimeDistributed, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "clean-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_difference(tensors):\n",
    "    x, y = tensors\n",
    "    return tf.abs(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coordinate-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_a = Input(shape=(max_length,), dtype='int32')\n",
    "hypothesis_a = Input(shape=(max_length,), dtype='int32')\n",
    "\n",
    "premise2_a = Embedding(vocab_size+1, \n",
    "                     embedding_hidden_size, \n",
    "                     weights=[embedding_matrix], \n",
    "                     input_length=max_length, \n",
    "                     trainable=False)(premise_a)\n",
    "hypothesis2_a = Embedding(vocab_size+1, \n",
    "                        embedding_hidden_size, \n",
    "                        weights=[embedding_matrix], \n",
    "                        input_length=max_length, \n",
    "                        trainable=False)(hypothesis_a)\n",
    "\n",
    "premise3_a = Dense(units=embedding_hidden_size, \n",
    "                   activation=activation_function)(premise2_a)\n",
    "hypothesis3_a = Dense(units=embedding_hidden_size, \n",
    "                    activation=activation_function)(hypothesis2_a)\n",
    "\n",
    "premise4_a = LSTM(units=embedding_hidden_size, \n",
    "                dropout=dropout_lstm)(premise3_a)\n",
    "hypothesis4_a = LSTM(units=embedding_hidden_size, \n",
    "                   dropout=dropout_lstm)(hypothesis3_a)\n",
    "\n",
    "premise5_a = BatchNormalization()(premise4_a)\n",
    "hypothesis5_a = BatchNormalization()(hypothesis4_a)\n",
    "\n",
    "joint_concatenate = concatenate([premise5_a, hypothesis5_a], axis=1)\n",
    "joint_concatenate2 = Dropout(dropout_rate)(joint_concatenate)\n",
    "\n",
    "joint_difference = Lambda(absolute_difference)([premise5_a, hypothesis5_a])\n",
    "joint_difference2 = Dropout(dropout_rate)(joint_difference)\n",
    "\n",
    "joint_multiplied = tf.keras.layers.Multiply()([premise5_a, hypothesis5_a])\n",
    "joint_multiplied2 = Dropout(dropout_rate)(joint_multiplied)\n",
    "\n",
    "all_concatenate = concatenate([joint_concatenate2, joint_difference2, joint_multiplied2], axis=1)\n",
    "all_concatenate2 = Dropout(dropout_rate)(all_concatenate)\n",
    "\n",
    "#####\n",
    "#for i in range(3):\n",
    "    #print(i)\n",
    "    #joint = joined_dense_layer(joint)\n",
    "    #joint = dropout_layer(joint)\n",
    "    #joint = batch_normalization(joint)\n",
    "\n",
    "####\n",
    "\n",
    "pred = Dense(units=n_labels, \n",
    "             activation=\"softmax\")(all_concatenate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wound-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 152)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 152, 300)     3903900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 152, 300)     3903900     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 152, 300)     90300       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 152, 300)     90300       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 300)          721200      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 300)          721200      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 300)          1200        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 600)          0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 300)          0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 300)          0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 600)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1200)         0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            3603        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,436,803\n",
      "Trainable params: 1,627,803\n",
      "Non-trainable params: 7,809,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conneau = Model(inputs=[premise_a, hypothesis_a], outputs=pred) \n",
    "model_conneau.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_conneau.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "canadian-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_path = \"training_4/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surface-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "45948/45948 [==============================] - 6202s 135ms/step - loss: 1.0986 - accuracy: 0.3344\n",
      "\n",
      "Epoch 00001: saving model to training_4/cp.ckpt\n",
      "Epoch 2/2\n",
      "45948/45948 [==============================] - 6525s 142ms/step - loss: 1.0986 - accuracy: 0.3335\n",
      "\n",
      "Epoch 00002: saving model to training_4/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb1b562fa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conneau.fit(x=[train_prem_encoded, train_hyp_encoded], \n",
    "                  y=train_labels, \n",
    "                  batch_size=1,\n",
    "                  epochs=2, \n",
    "                  verbose=1, \n",
    "                  callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "democratic-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9842/9842 [==============================] - 174s 18ms/step - loss: 1.0986 - accuracy: 0.3382\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_conneau.evaluate([dev_prem_encoded, dev_hyp_encoded], dev_labels, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beautiful-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986130237579346\n",
      "0.3382442593574524\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-string",
   "metadata": {},
   "source": [
    "### On the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "activated-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9824/9824 [==============================] - 12s 1ms/step - loss: 31.9547 - accuracy: 0.3683\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_sum_embeddings.evaluate([test_prem_encoded, test_hyp_encoded], test_labels, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "recent-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.9547119140625\n",
      "0.368281751871109\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
